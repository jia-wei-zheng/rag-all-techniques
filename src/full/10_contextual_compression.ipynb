{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 增强 RAG 系统的上下文压缩技术\n",
    "\n",
    "上下文情境压缩技术（Contextual Compression），以提高 RAG 系统的效率。过滤并压缩检索到的文本块，只保留最相关的内容，从而减少噪声并提高响应质量。\n",
    "\n",
    "在为 RAG 检索文档时，经常得到包含相关和不相关信息的块。上下文压缩可以帮助我们：\n",
    "\n",
    "- 删除无关的句子和段落\n",
    "- 仅关注与查询相关的信息\n",
    "- 在上下文窗口中最大化有用信号\n",
    "\n",
    "本文提供了三种方法：\n",
    "1. 过滤（selective）：分析文档块并仅提取与用户查询直接相关的句子或段落，移除所有无关内容。\n",
    "2. 摘要（summary）：创建文档块的简洁摘要，且仅聚焦与用户查询相关的信息。\n",
    "3. 抽取（extraction）：从文档块中精确提取与用户查询相关的完整句子。\n",
    "\n",
    "-----\n",
    "实现步骤：\n",
    "- 处理文档以创建向量存储：从PDF 中提取文本，分割文本块并创建向量存储\n",
    "- 创建查询嵌入并检索文档，检索最相似的前k个块\n",
    "- 对检索到的块应用压缩：\n",
    "    - 过滤（selective）：分析文档块并仅提取与用户查询直接相关的句子或段落，移除所有无关内容。\n",
    "    - 摘要（summary）：创建文档块的简洁摘要，且仅聚焦与用户查询相关的信息\n",
    "    - 抽取（extraction）：从文档块中精确提取与用户查询相关的完整句子\n",
    "- 过滤掉任何空的压缩块\n",
    "- 基于压缩块形成上下文内容，然后生成回答\n"
   ],
   "id": "71875fd1b20e57e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:24:39.820603Z",
     "start_time": "2025-04-25T02:24:37.286428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import fitz\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "2f7d25a79a557e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:24:43.664940Z",
     "start_time": "2025-04-25T02:24:43.324385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI(\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "    api_key=os.getenv(\"LLM_API_KEY\")\n",
    ")\n",
    "llm_model = os.getenv(\"LLM_MODEL_ID\")\n",
    "embedding_model = os.getenv(\"EMBEDDING_MODEL_ID\")\n",
    "\n",
    "pdf_path = \"../../data/AI_Information.en.zh-CN.pdf\""
   ],
   "id": "935d02c0a2e9342b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:24:45.657638Z",
     "start_time": "2025-04-25T02:24:45.652939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    从 PDF 文件中提取文本，并打印前 `num_chars` 个字符。\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    # 打开 PDF 文件\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # 初始化一个空字符串以存储提取的文本\n",
    "\n",
    "    # Iterate through each page in the PDF\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]\n",
    "        text = page.get_text(\"text\")  # 从页面中提取文本\n",
    "        all_text += text  # 将提取的文本追加到 all_text 字符串中\n",
    "\n",
    "    return all_text  # 返回提取的文本"
   ],
   "id": "bae415c1615302a5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:24:47.266607Z",
     "start_time": "2025-04-25T02:24:47.263018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    将文本分割为重叠的块\n",
    "\n",
    "    Args:\n",
    "    text (str): 要分割的文本\n",
    "    n (int): 每个块的字符数\n",
    "    overlap (int): 块之间的重叠字符数\n",
    "\n",
    "    Returns:\n",
    "    List[str]: 文本块列表\n",
    "    \"\"\"\n",
    "    chunks = []  #\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        # 添加从当前索引到索引 + 块大小的文本块\n",
    "        chunk = text[i:i + n]\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return chunks  # Return the list of text chunks"
   ],
   "id": "a70b2579bdf6b4f7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:24:48.420827Z",
     "start_time": "2025-04-25T02:24:48.415028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    使用NumPy实现的简单向量存储。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        初始化向量存储。\n",
    "        \"\"\"\n",
    "        self.vectors = []  # 用于存储嵌入向量的列表\n",
    "        self.texts = []  # 用于存储原始文本的列表\n",
    "        self.metadata = []  # 用于存储每个文本元数据的列表\n",
    "\n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        向向量存储中添加一个项目。\n",
    "\n",
    "        Args:\n",
    "        text (str): 原始文本。\n",
    "        embedding (List[float]): 嵌入向量。\n",
    "        metadata (dict, 可选): 额外的元数据。\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))  # 将嵌入转换为numpy数组并添加到向量列表中\n",
    "        self.texts.append(text)  # 将原始文本添加到文本列表中\n",
    "        self.metadata.append(metadata or {})  # 添加元数据到元数据列表中，如果没有提供则使用空字典\n",
    "\n",
    "    def similarity_search(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        查找与查询嵌入最相似的项目。\n",
    "\n",
    "        Args:\n",
    "        query_embedding (List[float]): 查询嵌入向量。\n",
    "        k (int): 返回的结果数量。\n",
    "\n",
    "        Returns:\n",
    "        List[Dict]: 包含文本和元数据的前k个最相似项。\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []  # 如果没有存储向量，则返回空列表\n",
    "\n",
    "        # 将查询嵌入转换为numpy数组\n",
    "        query_vector = np.array(query_embedding)\n",
    "\n",
    "        # 使用余弦相似度计算相似度\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            # 计算查询向量与存储向量之间的余弦相似度\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))  # 添加索引和相似度分数\n",
    "\n",
    "        # 按相似度排序（降序）\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 返回前k个结果\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],  # 添加对应的文本\n",
    "                \"metadata\": self.metadata[idx],  # 添加对应的元数据\n",
    "                \"similarity\": score  # 添加相似度分数\n",
    "            })\n",
    "\n",
    "        return results  # 返回前k个最相似项的列表\n"
   ],
   "id": "911984259cab54b6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:24:49.700351Z",
     "start_time": "2025-04-25T02:24:49.695568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_embeddings(text):\n",
    "    \"\"\"\n",
    "    使用Embedding模型为给定文本创建嵌入向量。\n",
    "\n",
    "    Args:\n",
    "        text (str): 要创建嵌入向量的输入文本。\n",
    "\n",
    "    Returns:\n",
    "        List[float]: 嵌入向量。\n",
    "    \"\"\"\n",
    "    # 通过将字符串输入转换为列表来处理字符串和列表输入\n",
    "    input_text = text if isinstance(text, list) else [text]\n",
    "\n",
    "    # 使用指定的模型为输入文本创建嵌入向量\n",
    "    response = client.embeddings.create(\n",
    "        model=embedding_model,\n",
    "        input=input_text\n",
    "    )\n",
    "\n",
    "    # 如果输入是字符串，仅返回第一个嵌入向量\n",
    "    if isinstance(text, str):\n",
    "        return response.data[0].embedding\n",
    "\n",
    "    # 否则，将所有嵌入向量作为向量列表返回\n",
    "    return [item.embedding for item in response.data]"
   ],
   "id": "af8b66dda22881d0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:24:52.549042Z",
     "start_time": "2025-04-25T02:24:52.544346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    为RAG处理文档。\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF文件的路径。\n",
    "        chunk_size (int): 每个文本块的大小（以字符为单位）。\n",
    "        chunk_overlap (int): 文本块之间的重叠大小（以字符为单位）。\n",
    "\n",
    "    Returns:\n",
    "        SimpleVectorStore: 包含文档文本块及其嵌入向量的向量存储。\n",
    "    \"\"\"\n",
    "    print(\"从PDF中提取文本...\")\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)  # 调用函数提取PDF中的文本\n",
    "\n",
    "    print(\"分割文本...\")\n",
    "    chunks = chunk_text(extracted_text, chunk_size, chunk_overlap)  # 将提取的文本分割为多个块\n",
    "    print(f\"创建了 {len(chunks)} 个文本块\")\n",
    "\n",
    "    print(\"为文本块创建嵌入向量...\")\n",
    "    # 为了提高效率，一次性为所有文本块创建嵌入向量\n",
    "    chunk_embeddings = create_embeddings(chunks)\n",
    "\n",
    "    # 创建向量存储\n",
    "    store = SimpleVectorStore()\n",
    "\n",
    "    # 将文本块添加到向量存储中\n",
    "    for i, (chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "        store.add_item(\n",
    "            text=chunk,  # 文本内容\n",
    "            embedding=embedding,  # 嵌入向量\n",
    "            metadata={\"index\": i, \"source\": pdf_path}  # 元数据，包括索引和源文件路径\n",
    "        )\n",
    "\n",
    "    print(f\"向向量存储中添加了 {len(chunks)} 个文本块\")\n",
    "    return store\n"
   ],
   "id": "d54ef76a5b603599",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 实现上下文压缩\n",
    "这是我们的方法的核心——我们将使用大语言模型 (LLM) 来过滤和压缩检索到的内容。"
   ],
   "id": "3a6795baceaea3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:24:56.299923Z",
     "start_time": "2025-04-25T02:24:56.295380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compress_chunk(chunk, query, compression_type=\"selective\"):\n",
    "    \"\"\"\n",
    "    压缩检索到的文本块，仅保留与查询相关的内容。\n",
    "\n",
    "    Args:\n",
    "        chunk (str): 要压缩的文本块\n",
    "        query (str): 用户查询\n",
    "        compression_type (str): 压缩类型 (\"selective\", \"summary\" 或 \"extraction\")\n",
    "\n",
    "    Returns:\n",
    "        str: 压缩后的文本块\n",
    "    \"\"\"\n",
    "    # 为不同的压缩方法定义系统提示\n",
    "    if compression_type == \"selective\":\n",
    "        system_prompt = \"\"\"您是专业信息过滤专家。\n",
    "        您的任务是分析文档块并仅提取与用户查询直接相关的句子或段落，移除所有无关内容。\n",
    "\n",
    "        输出要求：\n",
    "        1. 仅保留有助于回答查询的文本\n",
    "        2. 保持相关句子的原始措辞（禁止改写）\n",
    "        3. 维持文本的原始顺序\n",
    "        4. 包含所有相关文本（即使存在重复）\n",
    "        5. 排除任何与查询无关的文本\n",
    "\n",
    "        请以纯文本格式输出，不添加任何注释。\"\"\"\n",
    "\n",
    "    elif compression_type == \"summary\":\n",
    "        system_prompt = \"\"\"您是专业摘要生成专家。\n",
    "        您的任务是创建文档块的简洁摘要，且仅聚焦与用户查询相关的信息。\n",
    "\n",
    "        输出要求：\n",
    "        1. 保持简明扼要但涵盖所有相关要素\n",
    "        2. 仅聚焦与查询直接相关的信息\n",
    "        3. 省略无关细节\n",
    "        4. 使用中立、客观的陈述语气\n",
    "\n",
    "        请以纯文本格式输出，不添加任何注释。\"\"\"\n",
    "\n",
    "    else:  # extraction\n",
    "        system_prompt = \"\"\"您是精准信息提取专家。\n",
    "        您的任务是从文档块中精确提取与用户查询相关的完整句子。\n",
    "\n",
    "        输出要求：\n",
    "        1. 仅包含原始文本中的直接引用\n",
    "        2. 严格保持原始文本的措辞（禁止修改）\n",
    "        3. 仅选择与查询直接相关的完整句子\n",
    "        4. 不同句子使用换行符分隔\n",
    "        5. 不添加任何解释性文字\n",
    "\n",
    "        请以纯文本格式输出，不添加任何注释。\"\"\"\n",
    "\n",
    "    # 定义带有查询和文档块的用户提示\n",
    "    user_prompt = f\"\"\"\n",
    "        查询: {query}\n",
    "\n",
    "        文档块:\n",
    "        {chunk}\n",
    "\n",
    "        请严格提取与本查询相关的核心内容。\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用 OpenAI API 生成响应\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # 从响应中提取压缩后的文本块\n",
    "    compressed_chunk = response.choices[0].message.content.strip()\n",
    "\n",
    "    # 计算压缩比率\n",
    "    original_length = len(chunk)\n",
    "    compressed_length = len(compressed_chunk)\n",
    "    compression_ratio = (original_length - compressed_length) / original_length * 100\n",
    "\n",
    "    return compressed_chunk, compression_ratio\n"
   ],
   "id": "3a40d82630a9fa5b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 实现批量压缩\n",
    "为了提高效率，在尽可能的情况下一次性压缩多个文本块。"
   ],
   "id": "9252b04ab7273b87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:25:00.574665Z",
     "start_time": "2025-04-25T02:25:00.570231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_compress_chunks(chunks, query, compression_type=\"selective\"):\n",
    "    \"\"\"\n",
    "    逐个压缩多个文本块。\n",
    "\n",
    "    Args:\n",
    "        chunks (List[str]): 要压缩的文本块列表\n",
    "        query (str): 用户查询\n",
    "        compression_type (str): 压缩类型 (\"selective\", \"summary\", 或 \"extraction\")\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: 包含压缩比率的压缩文本块列表\n",
    "    \"\"\"\n",
    "    print(f\"正在压缩 {len(chunks)} 个文本块...\")  # 打印将要压缩的文本块数量\n",
    "    results = []  # 初始化一个空列表以存储结果\n",
    "    total_original_length = 0  # 初始化变量以存储所有文本块的原始总长度\n",
    "    total_compressed_length = 0  # 初始化变量以存储所有文本块的压缩后总长度\n",
    "\n",
    "    # 遍历每个文本块\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"正在压缩文本块 {i+1}/{len(chunks)}...\")  # 打印压缩进度\n",
    "        # 压缩文本块并获取压缩后的文本块和压缩比率\n",
    "        compressed_chunk, compression_ratio = compress_chunk(chunk, query, compression_type)\n",
    "        results.append((compressed_chunk, compression_ratio))  # 将结果添加到结果列表中\n",
    "\n",
    "        total_original_length += len(chunk)  # 将原始文本块的长度加到总原始长度中\n",
    "        total_compressed_length += len(compressed_chunk)  # 将压缩后文本块的长度加到总压缩长度中\n",
    "\n",
    "    # 计算总体压缩比率\n",
    "    overall_ratio = (total_original_length - total_compressed_length) / total_original_length * 100\n",
    "    print(f\"总体压缩比率: {overall_ratio:.2f}%\")  # 打印总体压缩比率\n",
    "\n",
    "    return results  # 返回包含压缩文本块和压缩比率的列表\n"
   ],
   "id": "a1732b040b6f2ff",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 生成回答",
   "id": "bd2401d95e3e6488"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:25:05.088289Z",
     "start_time": "2025-04-25T02:25:05.084737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_response(query, context):\n",
    "    \"\"\"\n",
    "    根据查询和上下文生成响应。\n",
    "\n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        context (str): 从压缩块中提取的上下文文本\n",
    "\n",
    "    Returns:\n",
    "        str: 生成的响应\n",
    "    \"\"\"\n",
    "    # 定义系统提示以指导AI的行为\n",
    "    system_prompt = \"您是一个乐于助人的AI助手。请仅根据提供的上下文来回答用户的问题。如果在上下文中找不到答案，请直接说'没有足够的信息'。\"\n",
    "\n",
    "    # 通过组合上下文和查询创建用户提示\n",
    "    user_prompt = f\"\"\"\n",
    "        上下文:\n",
    "        {context}\n",
    "\n",
    "        问题: {query}\n",
    "\n",
    "        请基于上述上下文内容提供一个全面详尽的答案。\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用OpenAI API生成响应\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # 返回生成的响应内容\n",
    "    return response.choices[0].message.content\n"
   ],
   "id": "da549684762a30cd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 上下文压缩的完整 RAG 管道",
   "id": "d27f5da2b3312680"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:25:09.872209Z",
     "start_time": "2025-04-25T02:25:09.867039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rag_with_compression(pdf_path, query, k=10, compression_type=\"selective\"):\n",
    "    \"\"\"\n",
    "    完整的RAG管道，包含上下文压缩。\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF文档的路径\n",
    "        query (str): 用户查询\n",
    "        k (int): 初始检索的块数量\n",
    "        compression_type (str): 压缩类型\n",
    "\n",
    "    Returns:\n",
    "        dict: 包括查询、压缩块和响应的结果\n",
    "    \"\"\"\n",
    "    print(\"\\n=== RAG WITH CONTEXTUAL COMPRESSION ===\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Compression type: {compression_type}\")\n",
    "\n",
    "    # 处理文档以提取文本、分块并创建嵌入\n",
    "    vector_store = process_document(pdf_path)\n",
    "\n",
    "    # 为查询创建嵌入\n",
    "    query_embedding = create_embeddings(query)\n",
    "\n",
    "    # 根据查询嵌入检索最相似的前k个块\n",
    "    print(f\"Retrieving top {k} chunks...\")\n",
    "    results = vector_store.similarity_search(query_embedding, k=k)\n",
    "    retrieved_chunks = [result[\"text\"] for result in results]\n",
    "\n",
    "    # 对检索到的块应用压缩\n",
    "    compressed_results = batch_compress_chunks(retrieved_chunks, query, compression_type)\n",
    "    compressed_chunks = [result[0] for result in compressed_results]\n",
    "    compression_ratios = [result[1] for result in compressed_results]\n",
    "\n",
    "    # 过滤掉任何空的压缩块\n",
    "    filtered_chunks = [(chunk, ratio) for chunk, ratio in zip(compressed_chunks, compression_ratios) if chunk.strip()]\n",
    "\n",
    "    if not filtered_chunks:\n",
    "        # 如果所有块都被压缩为空字符串，则使用原始块\n",
    "        print(\"Warning: All chunks were compressed to empty strings. Using original chunks.\")\n",
    "        filtered_chunks = [(chunk, 0.0) for chunk in retrieved_chunks]\n",
    "    else:\n",
    "        compressed_chunks, compression_ratios = zip(*filtered_chunks)\n",
    "\n",
    "    # 从压缩块生成上下文\n",
    "    context = \"\\n\\n---\\n\\n\".join(compressed_chunks)\n",
    "\n",
    "    # 基于压缩块生成响应\n",
    "    print(\"Generating response based on compressed chunks...\")\n",
    "    response = generate_response(query, context)\n",
    "\n",
    "    # 准备结果字典\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"original_chunks\": retrieved_chunks,\n",
    "        \"compressed_chunks\": compressed_chunks,\n",
    "        \"compression_ratios\": compression_ratios,\n",
    "        \"context_length_reduction\": f\"{sum(compression_ratios)/len(compression_ratios):.2f}%\",\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== RESPONSE ===\")\n",
    "    print(response)\n",
    "\n",
    "    return result\n"
   ],
   "id": "db58f6ae06ba255f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 标准RAG与压缩增强型RAG的对比分析\n",
    "构建对比函数实现标准RAG与压缩增强型RAG的性能比较："
   ],
   "id": "a3c19b0636f8dab3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:25:14.207231Z",
     "start_time": "2025-04-25T02:25:14.203300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def standard_rag(pdf_path, query, k=10):\n",
    "    \"\"\"\n",
    "    标准RAG，不包含压缩。\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF文档的路径\n",
    "        query (str): 用户查询\n",
    "        k (int): 检索的块数量\n",
    "\n",
    "    Returns:\n",
    "        dict: 包括查询、块和响应的结果\n",
    "    \"\"\"\n",
    "    print(\"\\n=== STANDARD RAG ===\")\n",
    "    print(f\"Query: {query}\")\n",
    "\n",
    "    # 处理文档以提取文本、分块并创建嵌入\n",
    "    vector_store = process_document(pdf_path)\n",
    "\n",
    "    # 为查询创建嵌入\n",
    "    query_embedding = create_embeddings(query)\n",
    "\n",
    "    # 根据查询嵌入检索最相似的前k个块\n",
    "    print(f\"Retrieving top {k} chunks...\")\n",
    "    results = vector_store.similarity_search(query_embedding, k=k)\n",
    "    retrieved_chunks = [result[\"text\"] for result in results]\n",
    "\n",
    "    # 从检索到的块生成上下文\n",
    "    context = \"\\n\\n---\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # 基于检索到的块生成响应\n",
    "    print(\"Generating response...\")\n",
    "    response = generate_response(query, context)\n",
    "\n",
    "    # 准备结果字典\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"chunks\": retrieved_chunks,\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== RESPONSE ===\")\n",
    "    print(response)\n",
    "\n",
    "    return result\n"
   ],
   "id": "7193df8461087bd7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "24280a7f7ac73004"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:25:16.345235Z",
     "start_time": "2025-04-25T02:25:16.341247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_responses(query, responses, reference_answer):\n",
    "    \"\"\"\n",
    "    评估多个响应与参考答案的对比。\n",
    "\n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        responses (Dict[str, str]): 按方法分类的响应字典\n",
    "        reference_answer (str): 参考答案\n",
    "\n",
    "    Returns:\n",
    "        str: 评估文本\n",
    "    \"\"\"\n",
    "    # 定义系统提示，指导AI的行为进行评估\n",
    "    system_prompt = \"\"\"您是RAG系统回答内容的客观评估专家。请对比分析同一查询的不同回答，判断哪项回答最精准、最全面且与查询最相关。\"\"\"\n",
    "\n",
    "    # 通过组合查询和参考答案创建用户提示\n",
    "    user_prompt = f\"\"\"\n",
    "    查询: {query}\n",
    "\n",
    "    参考答案: {reference_answer}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 将每个响应添加到提示中\n",
    "    for method, response in responses.items():\n",
    "        user_prompt += f\"\\n{method.capitalize()} 回答内容:\\n{response}\\n\"\n",
    "\n",
    "    # 在用户提示中添加评估标准\n",
    "    user_prompt += \"\"\"\n",
    "    请基于以下维度评估各项回答：\n",
    "    1. 事实准确性（对照参考答案）\n",
    "    2. 回答完整度（是否全面解答问题）\n",
    "    3. 内容精简度（是否避免无关信息）\n",
    "    4. 综合质量\n",
    "\n",
    "    具体要求：\n",
    "    - 对所有回答进行排序（从最优到最差）\n",
    "    - 提供详细的评估依据\n",
    "    - 指出各项回答的优缺点\n",
    "    - 最终推荐最优解决方案\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用AI API生成评估响应\n",
    "    evaluation_response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # 返回响应中的评估文本\n",
    "    return evaluation_response.choices[0].message.content\n"
   ],
   "id": "caf0766d1e59306b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:25:22.105417Z",
     "start_time": "2025-04-25T02:25:22.100505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_compression(pdf_path, query, reference_answer=None, compression_types=[\"selective\", \"summary\", \"extraction\"]):\n",
    "    \"\"\"\n",
    "    比较不同的压缩技术与标准RAG。\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF文档的路径\n",
    "        query (str): 用户查询\n",
    "        reference_answer (str): 可选的参考答案\n",
    "        compression_types (List[str]): 要评估的压缩类型列表\n",
    "\n",
    "    Returns:\n",
    "        dict: 评估结果\n",
    "    \"\"\"\n",
    "    print(\"\\n=== 正在评估上下文压缩 ===\")\n",
    "    print(f\"查询: {query}\")\n",
    "\n",
    "    # 运行标准RAG（无压缩）\n",
    "    standard_result = standard_rag(pdf_path, query)\n",
    "\n",
    "    # 存储不同压缩技术结果的字典\n",
    "    compression_results = {}\n",
    "\n",
    "    # 使用每种压缩技术运行RAG\n",
    "    for comp_type in compression_types:\n",
    "        print(f\"\\n正在测试 {comp_type} 压缩...\")\n",
    "        compression_results[comp_type] = rag_with_compression(pdf_path, query, compression_type=comp_type)\n",
    "\n",
    "    # 收集响应以进行评估\n",
    "    responses = {\n",
    "        \"standard\": standard_result[\"response\"]\n",
    "    }\n",
    "    for comp_type in compression_types:\n",
    "        responses[comp_type] = compression_results[comp_type][\"response\"]\n",
    "\n",
    "    # 如果提供了参考答案，则评估响应\n",
    "    if reference_answer:\n",
    "        evaluation = evaluate_responses(query, responses, reference_answer)\n",
    "        print(\"\\n=== 评估结果 ===\")\n",
    "        print(evaluation)\n",
    "    else:\n",
    "        evaluation = \"未提供参考答案进行评估。\"\n",
    "\n",
    "    # 计算每种压缩类型的指标\n",
    "    metrics = {}\n",
    "    for comp_type in compression_types:\n",
    "        metrics[comp_type] = {\n",
    "            \"avg_compression_ratio\": f\"{sum(compression_results[comp_type]['compression_ratios'])/len(compression_results[comp_type]['compression_ratios']):.2f}%\",\n",
    "            \"total_context_length\": len(\"\\n\\n\".join(compression_results[comp_type]['compressed_chunks'])),\n",
    "            \"original_context_length\": len(\"\\n\\n\".join(standard_result['chunks']))\n",
    "        }\n",
    "\n",
    "    # 返回评估结果、响应和指标\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"responses\": responses,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"metrics\": metrics,\n",
    "        \"standard_result\": standard_result,\n",
    "        \"compression_results\": compression_results\n",
    "    }\n"
   ],
   "id": "474c3797965226b9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 运行我们的完整系统（自定义查询）",
   "id": "5dda7e90f7d10d04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:32:44.818640Z",
     "start_time": "2025-04-25T02:25:36.302157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 从文档中提取相关信息的查询\n",
    "query = \"人工智能在决策应用中的伦理有哪些问题？\"\n",
    "\n",
    "# 可选的参考答案，用于评估\n",
    "reference_answer = \"\"\"\n",
    "人工智能在决策中的应用引发多个伦理问题：\n",
    "- AI模型偏见可能导致不公正或歧视性结果，在招聘、信贷发放及执法等关键领域尤为突出\n",
    "- AI驱动中的黑箱决策机制使得个体难以质疑不公正结果，透明度和可解释性不足\n",
    "- AI系统处理海量个人数据时存在隐私泄露风险，通常缺乏明确授权\n",
    "- 自动化导致的岗位流失引发社会经济层面的担忧\n",
    "- AI决策权可能集中于少数科技巨头，导致问责机制失效\n",
    "- 确保AI系统的公平性、问责机制和系统透明度是实现伦理部署的必要条件\n",
    "\"\"\"\n",
    "\n",
    "# 使用不同的压缩技术进行评估\n",
    "# 压缩类型：\n",
    "# - \"selective\": 保留关键细节，省略不太相关的内容\n",
    "# - \"summary\": 提供信息的简洁版本\n",
    "# - \"extraction\": 从文档中逐字提取相关句子\n",
    "results = evaluate_compression(\n",
    "    pdf_path=pdf_path,  # PDF文件路径\n",
    "    query=query,  # 查询内容\n",
    "    reference_answer=reference_answer,  # 参考答案\n",
    "    compression_types=[\"selective\", \"summary\", \"extraction\"]  # 压缩类型列表\n",
    ")\n"
   ],
   "id": "4499199508c451b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 正在评估上下文压缩 ===\n",
      "查询: 人工智能在决策应用中的伦理有哪些问题？\n",
      "\n",
      "=== STANDARD RAG ===\n",
      "Query: 人工智能在决策应用中的伦理有哪些问题？\n",
      "从PDF中提取文本...\n",
      "分割文本...\n",
      "创建了 13 个文本块\n",
      "为文本块创建嵌入向量...\n",
      "向向量存储中添加了 13 个文本块\n",
      "Retrieving top 10 chunks...\n",
      "Generating response...\n",
      "\n",
      "=== RESPONSE ===\n",
      "根据上下文内容，人工智能在决策应用中的伦理问题主要包括以下几个方面：\n",
      "\n",
      "### 1. **偏见与公平性**\n",
      "- **问题**：AI系统可能继承并放大训练数据中存在的偏见，导致歧视性或不公平的决策结果。例如，在招聘、信贷审批或司法预测中，历史数据中的偏见可能导致对特定群体的不公平对待。\n",
      "- **解决方向**：需通过谨慎的数据收集、算法设计优化（如去偏技术）以及持续的监测评估来减少偏见。\n",
      "\n",
      "### 2. **透明度和可解释性**\n",
      "- **问题**：许多AI系统（尤其是深度学习模型）是“黑匣子”，其决策过程难以理解。缺乏透明度会削弱用户信任，并妨碍对错误决策的追责。\n",
      "- **解决方向**：发展可解释人工智能（XAI）技术，通过可视化、简化模型或生成决策理由来增强可解释性。\n",
      "\n",
      "### 3. **隐私和数据安全**\n",
      "- **问题**：AI决策依赖大量数据，可能涉及敏感信息（如医疗记录、财务数据）。不当的数据处理或泄露会侵犯隐私权。\n",
      "- **解决方向**：采用隐私保护技术（如差分隐私、联邦学习），并遵守数据保护法规（如GDPR）。\n",
      "\n",
      "### 4. **问责与责任归属**\n",
      "- **问题**：当AI决策导致负面后果（如自动驾驶事故或医疗误诊），责任主体不明确（开发者、部署者或用户）。\n",
      "- **解决方向**：需建立明确的法律框架，界定各方的角色与责任，并确保AI系统具备可追溯性。\n",
      "\n",
      "### 5. **自主性与人类控制**\n",
      "- **问题**：高度自主的AI系统可能脱离人类监管，产生不可预测的后果（如军事武器系统失控）。\n",
      "- **解决方向**：制定开发指导方针（如“人类监督”原则），确保关键决策中保留人类否决权。\n",
      "\n",
      "### 6. **社会影响与工作岗位流失**\n",
      "- **问题**：AI自动化决策可能取代人类岗位（如客服、制造业），引发经济不平等和社会动荡。\n",
      "- **解决方向**：推动劳动力再培训计划，促进人机协作模式，并探索AI创造的新就业机会。\n",
      "\n",
      "### 7. **伦理框架与全球协作**\n",
      "- **问题**：不同地区对AI伦理的认知和标准存在差异，可能导致监管冲突或“伦理洼地”。\n",
      "- **解决方向**：推动国际合作（如制定全球性AI伦理准则），确保跨文化、跨领域的伦理共识。\n",
      "\n",
      "### 总结\n",
      "解决这些伦理问题需要多管齐下，包括技术创新（如XAI）、政策监管（如数据保护法）、行业自律（如伦理审查委员会）以及公众教育。上下文中强调的“负责任AI”原则（公平、透明、隐私、问责）是核心指导方针，而全球协作与持续研究是长期保障。\n",
      "\n",
      "正在测试 selective 压缩...\n",
      "\n",
      "=== RAG WITH CONTEXTUAL COMPRESSION ===\n",
      "Query: 人工智能在决策应用中的伦理有哪些问题？\n",
      "Compression type: selective\n",
      "从PDF中提取文本...\n",
      "分割文本...\n",
      "创建了 13 个文本块\n",
      "为文本块创建嵌入向量...\n",
      "向向量存储中添加了 13 个文本块\n",
      "Retrieving top 10 chunks...\n",
      "正在压缩 10 个文本块...\n",
      "正在压缩文本块 1/10...\n",
      "正在压缩文本块 2/10...\n",
      "正在压缩文本块 3/10...\n",
      "正在压缩文本块 4/10...\n",
      "正在压缩文本块 5/10...\n",
      "正在压缩文本块 6/10...\n",
      "正在压缩文本块 7/10...\n",
      "正在压缩文本块 8/10...\n",
      "正在压缩文本块 9/10...\n",
      "正在压缩文本块 10/10...\n",
      "总体压缩比率: 78.22%\n",
      "Generating response based on compressed chunks...\n",
      "\n",
      "=== RESPONSE ===\n",
      "根据上下文内容，人工智能在决策应用中的伦理问题主要包括以下几个方面：\n",
      "\n",
      "### 1. **偏见与公平性**\n",
      "   - **问题**：人工智能系统可能继承并放大训练数据中的偏见，导致不公平或歧视性决策结果。\n",
      "   - **表现**：例如在招聘、信贷审批或司法决策中，算法可能因历史数据中的偏见而歧视特定群体。\n",
      "   - **解决方向**：需通过谨慎的数据收集、算法设计优化以及持续的监测和评估来减少偏见。\n",
      "\n",
      "### 2. **透明度和可解释性**\n",
      "   - **问题**：许多AI决策系统（如深度学习模型）是“黑匣子”，难以理解其决策逻辑。\n",
      "   - **风险**：缺乏透明度会削弱用户信任，并妨碍对错误决策的追责。\n",
      "   - **解决方案**：开发可解释人工智能（XAI）技术，使决策过程更透明易懂，确保用户能评估其公平性和准确性。\n",
      "\n",
      "### 3. **隐私和数据安全**\n",
      "   - **问题**：AI决策依赖大量数据，可能侵犯个人隐私或引发数据滥用风险。\n",
      "   - **挑战**：例如医疗或金融领域的敏感信息处理需高度谨慎。\n",
      "   - **应对措施**：需实施隐私保护技术、遵守数据保护法规（如GDPR），并确保数据处理的透明性。\n",
      "\n",
      "### 4. **自主性与控制**\n",
      "   - **问题**：高度自主的AI系统可能脱离人类控制，导致意外后果或责任归属不清。\n",
      "   - **案例**：自动驾驶汽车的道德决策（如“电车难题”）或军事武器的自主化应用。\n",
      "   - **伦理框架**：需制定国际法规和道德准则，明确开发者和部署者的责任边界。\n",
      "\n",
      "### 5. **问责与责任**\n",
      "   - **问题**：当AI决策造成危害时，责任主体（开发者、部署者或用户）难以界定。\n",
      "   - **需求**：需建立明确的问责机制，确保受害者获得救济，并推动伦理合规。\n",
      "\n",
      "### 6. **社会影响与权利保护**\n",
      "   - **问题**：AI决策可能加剧社会不平等（如自动化导致失业）或侵犯人权。\n",
      "   - **原则**：需以“以人为本的AI”为核心，确保系统符合人类价值观，优先保护隐私、非歧视和福祉。\n",
      "\n",
      "### 7. **武器化的伦理风险**\n",
      "   - **特殊领域**：AI在自主武器中的应用涉及生命权剥夺的伦理困境。\n",
      "   - **国际共识**：需通过全球合作禁止或严格限制此类用途，防止滥用。\n",
      "\n",
      "### 总结性伦理原则\n",
      "根据上下文，伦理AI决策应遵循以下核心原则：\n",
      "- **公平性**：避免偏见和歧视。\n",
      "- **透明性**：确保决策可解释。\n",
      "- **隐私保护**：安全处理数据。\n",
      "- **问责制**：明确责任划分。\n",
      "- **人权尊重**：优先保护人类权益。\n",
      "- **社会效益**：以促进福祉为目标。\n",
      "\n",
      "这些问题的解决需要跨学科合作、国际标准制定以及持续的伦理审查机制。\n",
      "\n",
      "正在测试 summary 压缩...\n",
      "\n",
      "=== RAG WITH CONTEXTUAL COMPRESSION ===\n",
      "Query: 人工智能在决策应用中的伦理有哪些问题？\n",
      "Compression type: summary\n",
      "从PDF中提取文本...\n",
      "分割文本...\n",
      "创建了 13 个文本块\n",
      "为文本块创建嵌入向量...\n",
      "向向量存储中添加了 13 个文本块\n",
      "Retrieving top 10 chunks...\n",
      "正在压缩 10 个文本块...\n",
      "正在压缩文本块 1/10...\n",
      "正在压缩文本块 2/10...\n",
      "正在压缩文本块 3/10...\n",
      "正在压缩文本块 4/10...\n",
      "正在压缩文本块 5/10...\n",
      "正在压缩文本块 6/10...\n",
      "正在压缩文本块 7/10...\n",
      "正在压缩文本块 8/10...\n",
      "正在压缩文本块 9/10...\n",
      "正在压缩文本块 10/10...\n",
      "总体压缩比率: 87.67%\n",
      "Generating response based on compressed chunks...\n",
      "\n",
      "=== RESPONSE ===\n",
      "基于提供的上下文内容，人工智能在决策应用中的伦理问题可系统归纳为以下核心方面：\n",
      "\n",
      "---\n",
      "\n",
      "### **1. 偏见与公平性**\n",
      "- **数据偏见放大**：AI可能继承并放大训练数据中的历史或社会偏见（如种族、性别歧视），导致不公平决策结果（如招聘、信贷审批）。\n",
      "- **算法歧视**：设计缺陷或数据选择不当可能使特定群体受到系统性歧视，需通过公平性算法和偏见检测工具缓解。\n",
      "\n",
      "---\n",
      "\n",
      "### **2. 透明性与可解释性（XAI）**\n",
      "- **\"黑匣子\"问题**：深度学习模型决策过程难以追溯，需发展可解释人工智能（XAI）技术以提高透明度。\n",
      "- **信任建立**：用户需理解AI决策逻辑以评估其合理性，尤其在医疗、司法等高风险领域。\n",
      "\n",
      "---\n",
      "\n",
      "### **3. 隐私与数据安全**\n",
      "- **数据依赖风险**：AI依赖大量个人数据，可能违反隐私法规（如GDPR），需匿名化处理和加密技术保护。\n",
      "- **滥用潜在**：数据泄露或监控滥用可能侵犯人权，需严格的数据治理框架。\n",
      "\n",
      "---\n",
      "\n",
      "### **4. 自主性与责任归属**\n",
      "- **失控风险**：高度自主的AI系统（如自动驾驶、无人机）可能引发不可预测行为，需明确人类监督机制。\n",
      "- **问责空白**：当AI决策造成损害时，责任划分困难（开发者、部署者或用户），需法律明确责任链条。\n",
      "\n",
      "---\n",
      "\n",
      "### **5. 武器化与安全威胁**\n",
      "- **自主武器伦理**：致命性自主武器系统（LAWS）可能绕过人类判断，引发战争伦理争议，需国际公约限制。\n",
      "- **恶意使用**：AI可能被用于网络攻击或深度伪造，需全球协作制定安全标准。\n",
      "\n",
      "---\n",
      "\n",
      "### **6. 就业与社会影响**\n",
      "- **劳动力替代**：自动化导致就业流失，需政策干预（如再培训计划）和\"人机协作\"伦理框架。\n",
      "- **工人权利保护**：AI监控员工绩效可能侵犯隐私，需平衡效率与权利。\n",
      "\n",
      "---\n",
      "\n",
      "### **7. 道德框架与全球治理**\n",
      "- **伦理原则缺失**：需制定公平、透明、问责的伦理准则（如OECD AI原则），并嵌入系统设计阶段。\n",
      "- **国际合作需求**：跨国标准不一致可能加剧风险，需联合国等机构推动协同治理（如数据主权、算法审计）。\n",
      "\n",
      "---\n",
      "\n",
      "### **8. 用户权利与人性化设计**\n",
      "- **知情与选择权**：用户应有权知晓AI参与决策并选择退出（如个性化推荐）。\n",
      "- **以人为本**：AI开发需考量社会心理影响，优先保障人类尊严和福祉（如避免情感操纵）。\n",
      "\n",
      "---\n",
      "\n",
      "### **总结**\n",
      "这些问题相互交织，需多学科协作（技术、法律、哲学）和动态监管解决。核心矛盾在于平衡AI的创新潜力与对人类社会价值观的保护，最终目标是实现**负责任的人工智能（Responsible AI）**。\n",
      "\n",
      "正在测试 extraction 压缩...\n",
      "\n",
      "=== RAG WITH CONTEXTUAL COMPRESSION ===\n",
      "Query: 人工智能在决策应用中的伦理有哪些问题？\n",
      "Compression type: extraction\n",
      "从PDF中提取文本...\n",
      "分割文本...\n",
      "创建了 13 个文本块\n",
      "为文本块创建嵌入向量...\n",
      "向向量存储中添加了 13 个文本块\n",
      "Retrieving top 10 chunks...\n",
      "正在压缩 10 个文本块...\n",
      "正在压缩文本块 1/10...\n",
      "正在压缩文本块 2/10...\n",
      "正在压缩文本块 3/10...\n",
      "正在压缩文本块 4/10...\n",
      "正在压缩文本块 5/10...\n",
      "正在压缩文本块 6/10...\n",
      "正在压缩文本块 7/10...\n",
      "正在压缩文本块 8/10...\n",
      "正在压缩文本块 9/10...\n",
      "正在压缩文本块 10/10...\n",
      "总体压缩比率: 83.68%\n",
      "Generating response based on compressed chunks...\n",
      "\n",
      "=== RESPONSE ===\n",
      "根据上下文，人工智能在决策应用中的伦理问题主要包括以下几个方面：\n",
      "\n",
      "1. **偏见与公平性**  \n",
      "   - 人工智能系统可能继承并放大训练数据中的偏见，导致不公平或歧视性结果。  \n",
      "   - 解决需要谨慎的数据收集、算法设计及持续的监测和评估。\n",
      "\n",
      "2. **透明度与可解释性**  \n",
      "   - 许多AI系统（如深度学习模型）是“黑匣子”，决策过程难以理解。  \n",
      "   - 可解释人工智能（XAI）技术旨在提升透明度，帮助用户评估决策的公平性和准确性。\n",
      "\n",
      "3. **隐私与数据安全**  \n",
      "   - AI依赖大量数据，可能引发隐私泄露风险。  \n",
      "   - 需确保敏感信息保护及负责任的数据处理。\n",
      "\n",
      "4. **问责制与责任归属**  \n",
      "   - 随着AI自主性增强，需明确开发者、部署者和用户的责任。  \n",
      "   - 建立问责机制以应对潜在危害和道德问题。\n",
      "\n",
      "5. **自主武器系统的伦理争议**  \n",
      "   - 军事应用引发重大安全担忧，需国际法规约束其风险。\n",
      "\n",
      "6. **伦理框架与治理缺失**  \n",
      "   - 当前缺乏统一的道德准则和监管标准，需制定指导方针以确保开发符合人权、非歧视等原则。\n",
      "\n",
      "7. **社会与心理影响**  \n",
      "   - 需考量AI对就业、人类福祉的影响，优先以人为中心的设计。\n",
      "\n",
      "综上，解决这些问题需结合伦理评估、利益相关者协商及跨领域合作，以平衡创新与社会效益。\n",
      "\n",
      "=== 评估结果 ===\n",
      "### 评估结果排序（从最优到最差）：\n",
      "1. **Summary 回答内容**\n",
      "2. **Standard 回答内容**\n",
      "3. **Selective 回答内容**\n",
      "4. **Extraction 回答内容**\n",
      "\n",
      "---\n",
      "\n",
      "### 详细评估依据\n",
      "\n",
      "#### **1. Summary 回答内容**  \n",
      "**优点：**  \n",
      "- **事实准确性**：完全覆盖参考答案的所有核心问题（偏见、透明度、隐私、问责等），并补充了参考答案未提及的“武器化与安全威胁”“就业与社会影响”等细分领域。  \n",
      "- **回答完整度**：最全面，将伦理问题归纳为8个系统化维度，每个维度包含问题描述、风险案例和解决方向，逻辑清晰。  \n",
      "- **内容精简度**：虽内容详细，但无冗余信息，通过分级标题和分点排版提升可读性。  \n",
      "- **综合质量**：提出“负责任的人工智能”总结框架，体现跨学科协作和动态监管的前瞻性。  \n",
      "\n",
      "**缺点**：部分子项（如“武器化”）的解决方向可更具体。\n",
      "\n",
      "---\n",
      "\n",
      "#### **2. Standard 回答内容**  \n",
      "**优点：**  \n",
      "- **事实准确性**：涵盖参考答案全部要点，额外补充“伦理框架与全球协作”这一重要维度。  \n",
      "- **回答完整度**：7个问题分类合理，每个问题均提供“解决方向”，实用性较强。  \n",
      "- **内容精简度**：结构清晰，但部分子项（如“社会影响”）的论述略简略。  \n",
      "\n",
      "**缺点**：相比Summary回答，缺少“武器化”“数据主权”等前沿议题的深入分析。\n",
      "\n",
      "---\n",
      "\n",
      "#### **3. Selective 回答内容**  \n",
      "**优点：**  \n",
      "- **事实准确性**：覆盖参考答案核心内容，但未提及“岗位流失”等社会经济影响。  \n",
      "- **回答完整度**：7个问题分类与Standard类似，但“武器化的伦理风险”独立成项，体现一定创新性。  \n",
      "- **内容精简度**：部分子项（如“隐私和数据安全”）重复提及GDPR，略显冗余。  \n",
      "\n",
      "**缺点**：总结部分仅罗列原则，未提出具体实施路径，完整性稍逊。\n",
      "\n",
      "---\n",
      "\n",
      "#### **4. Extraction 回答内容**  \n",
      "**优点：**  \n",
      "- **事实准确性**：包含参考答案主要问题，但“自主武器”仅一句话带过，缺乏深度。  \n",
      "- **回答完整度**：7点分类较笼统，如“社会与心理影响”未展开就业等具体案例。  \n",
      "- **内容精简度**：过于简略，部分要点（如“伦理框架”）仅提及“缺失”，未提供解决建议。  \n",
      "\n",
      "**缺点**：整体流于表面，缺乏案例和解决方案的实质性内容。\n",
      "\n",
      "---\n",
      "\n",
      "### 最优解决方案推荐  \n",
      "**推荐采用「Summary 回答内容」**，因其具备以下优势：  \n",
      "1. **全面性与前瞻性**：覆盖传统伦理问题（如偏见、隐私）和新兴挑战（如武器化、全球治理），符合技术发展趋势。  \n",
      "2. **结构化表达**：通过分级标题和分点论述，兼顾专业性与可读性，适合不同受众。  \n",
      "3. **解决方案导向**：每个问题均提供缓解措施（如XAI技术、国际公约），可直接指导实践。  \n",
      "\n",
      "**改进建议**：可补充“伦理审查流程”的具体案例（如欧盟AI法案），进一步增强实操性。\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 可视化压缩结果",
   "id": "dc560bf8b2af5d06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:34:31.262896Z",
     "start_time": "2025-04-25T02:34:31.256074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_compression_results(evaluation_results):\n",
    "    \"\"\"\n",
    "    可视化不同压缩技术的结果。\n",
    "\n",
    "    Args:\n",
    "        evaluation_results (Dict): 来自 evaluate_compression 函数的结果\n",
    "    \"\"\"\n",
    "    # 从评估结果中提取查询和标准块\n",
    "    query = evaluation_results[\"query\"]\n",
    "    standard_chunks = evaluation_results[\"standard_result\"][\"chunks\"]\n",
    "\n",
    "    # 打印查询内容\n",
    "    print(f\"Query: {query}\")  # 查询内容\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")  # 分隔线\n",
    "\n",
    "    # 获取一个示例块以进行可视化（使用第一个块）\n",
    "    original_chunk = standard_chunks[0]\n",
    "\n",
    "    # 遍历每种压缩类型并显示比较结果\n",
    "    for comp_type in evaluation_results[\"compression_results\"].keys():\n",
    "        compressed_chunks = evaluation_results[\"compression_results\"][comp_type][\"compressed_chunks\"]\n",
    "        compression_ratios = evaluation_results[\"compression_results\"][comp_type][\"compression_ratios\"]\n",
    "\n",
    "        # 获取对应的压缩块及其压缩比率\n",
    "        compressed_chunk = compressed_chunks[0]\n",
    "        compression_ratio = compression_ratios[0]\n",
    "\n",
    "        print(f\"\\n=== {comp_type.upper()} COMPRESSION EXAMPLE ===\\n\")  # 压缩类型的标题\n",
    "\n",
    "        # 显示原始块（如果过长则截断）\n",
    "        print(\"ORIGINAL CHUNK:\")  # 标题：原始块\n",
    "        print(\"-\" * 40)  # 分隔线\n",
    "        if len(original_chunk) > 800:  # 如果原始块长度超过 800 字符，则截断\n",
    "            print(original_chunk[:800] + \"... [truncated]\")  # 截断后的文本\n",
    "        else:\n",
    "            print(original_chunk)  # 完整的原始块\n",
    "        print(\"-\" * 40)  # 分隔线\n",
    "        print(f\"Length: {len(original_chunk)} characters\\n\")  # 原始块的长度\n",
    "\n",
    "        # 显示压缩块\n",
    "        print(\"COMPRESSED CHUNK:\")  # 标题：压缩块\n",
    "        print(\"-\" * 40)  # 分隔线\n",
    "        print(compressed_chunk)  # 压缩后的文本\n",
    "        print(\"-\" * 40)  # 分隔线\n",
    "        print(f\"Length: {len(compressed_chunk)} characters\")  # 压缩块的长度\n",
    "        print(f\"Compression ratio: {compression_ratio:.2f}%\\n\")  # 压缩比率\n",
    "\n",
    "        # 显示该压缩类型的总体统计数据\n",
    "        avg_ratio = sum(compression_ratios) / len(compression_ratios)  # 平均压缩比率\n",
    "        print(f\"Average compression across all chunks: {avg_ratio:.2f}%\")  # 所有块的平均压缩比率\n",
    "        print(f\"Total context length reduction: {evaluation_results['metrics'][comp_type]['avg_compression_ratio']}\")  # 总上下文长度减少\n",
    "        print(\"=\" * 80)  # 分隔线\n",
    "\n",
    "    # 显示压缩技术的汇总表\n",
    "    print(\"\\n=== COMPRESSION SUMMARY ===\\n\")  # 汇总标题\n",
    "    print(f\"{'Technique':<15} {'Avg Ratio':<15} {'Context Length':<15} {'Original Length':<15}\")  # 表头\n",
    "    print(\"-\" * 60)  # 分隔线\n",
    "\n",
    "    # 打印每种压缩技术的指标\n",
    "    for comp_type, metrics in evaluation_results[\"metrics\"].items():\n",
    "        print(f\"{comp_type:<15} {metrics['avg_compression_ratio']:<15} {metrics['total_context_length']:<15} {metrics['original_context_length']:<15}\")  # 每种技术的详细数据\n"
   ],
   "id": "b45115f3b474393a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T02:34:32.822291Z",
     "start_time": "2025-04-25T02:34:32.818817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize the compression results\n",
    "visualize_compression_results(results)"
   ],
   "id": "9b6cdc7dc37d7dc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 人工智能在决策应用中的伦理有哪些问题？\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "=== SELECTIVE COMPRESSION EXAMPLE ===\n",
      "\n",
      "ORIGINAL CHUNK:\n",
      "----------------------------------------\n",
      "问题也随之⽽来。为⼈⼯智能的开发\n",
      "和部署建⽴清晰的指导⽅针和道德框架⾄关重要。\n",
      "⼈⼯智能武器化\n",
      "⼈⼯智能在⾃主武器系统中的潜在应⽤引发了重⼤的伦理和安全担忧。需要开展国际讨论并制定相\n",
      "关法规，以应对⼈⼯智能武器的相关⻛险。\n",
      "第五章：⼈⼯智能的未来\n",
      "⼈⼯智能的未来很可能以持续进步和在各个领域的⼴泛应⽤为特征。关键趋势和发展领域包括：\n",
      "可解释⼈⼯智能（XAI）\n",
      "可解释⼈⼯智能 (XAI) 旨在使⼈⼯智能系统更加透明易懂。XAI 技术正在开发中，旨在深⼊了解⼈\n",
      "⼯智能模型的决策⽅式，从⽽增强信任度和责任感。\n",
      "边缘⼈⼯智能\n",
      "边缘⼈⼯智能是指在设备上本地处理数据，⽽不是依赖云服务器。这种⽅法可以减少延迟，增强隐\n",
      "私保护，并在连接受限的环境中⽀持⼈⼯智能应⽤。\n",
      "量⼦计算和⼈⼯智能\n",
      "量⼦计算有望显著加速⼈⼯智能算法，从⽽推动药物研发、材料科学和优化等领域的突破。量⼦计\n",
      "算与⼈⼯智能的交叉研究前景⼴阔。\n",
      "⼈机协作\n",
      "⼈⼯智能的未来很可能涉及⼈类与⼈⼯智能系统之间更紧密的协作。这包括开发能够增强⼈类能\n",
      "⼒、⽀持决策和提⾼⽣产⼒的⼈⼯智能⼯具。\n",
      "⼈⼯智能造福社会\n",
      "⼈⼯智能正⽇益被⽤于应对社会和环境挑战，例如⽓候变化、贫困和医疗保健差距。“⼈⼯智能造\n",
      "福社会”倡议旨在利⽤⼈⼯智能产⽣积极影响。\n",
      "监管与治理\n",
      "随着⼈⼯智能⽇益普及，监管和治理的需求将⽇益增⻓，以确保负责任的开发和部署。这包括制定\n",
      "道德准则、解决偏⻅和公平问题，以及保护隐私和安全。国际标准合作⾄关重要。\n",
      "通过了解⼈⼯智能的核⼼概念、应⽤、伦理影响和未来发展⽅向，我们可以更好地应对这项变⾰性\n",
      "技术带来的机遇和挑战。持续的研究、负责任的开发和周到的治理，对于充分发挥⼈⼯智能的潜⼒\n",
      "并降低其⻛险⾄关重要。\n",
      "第六章：⼈⼯智能和机器⼈技术\n",
      "⼈⼯智能与机器⼈技术的融合\n",
      "⼈⼯智能与机器⼈技术的融合，将机器⼈的物理能⼒与⼈⼯智能的认知能⼒完美结合。这种... [truncated]\n",
      "----------------------------------------\n",
      "Length: 1000 characters\n",
      "\n",
      "COMPRESSED CHUNK:\n",
      "----------------------------------------\n",
      "为⼈⼯智能的开发\n",
      "和部署建⽴清晰的指导⽅针和道德框架⾄关重要。\n",
      "⼈⼯智能武器化\n",
      "⼈⼯智能在⾃主武器系统中的潜在应⽤引发了重⼤的伦理和安全担忧。需要开展国际讨论并制定相\n",
      "关法规，以应对⼈⼯智能武器的相关⻛险。\n",
      "可解释⼈⼯智能（XAI）\n",
      "可解释⼈⼯智能 (XAI) 旨在使⼈⼯智能系统更加透明易懂。XAI 技术正在开发中，旨在深⼊了解⼈\n",
      "⼯智能模型的决策⽅式，从⽽增强信任度和责任感。\n",
      "监管与治理\n",
      "随着⼈⼯智能⽇益普及，监管和治理的需求将⽇益增⻓，以确保负责任的开发和部署。这包括制定\n",
      "道德准则、解决偏⻅和公平问题，以及保护隐私和安全。国际标准合作⾄关重要。\n",
      "----------------------------------------\n",
      "Length: 277 characters\n",
      "Compression ratio: 72.30%\n",
      "\n",
      "Average compression across all chunks: 77.73%\n",
      "Total context length reduction: 77.73%\n",
      "================================================================================\n",
      "\n",
      "=== SUMMARY COMPRESSION EXAMPLE ===\n",
      "\n",
      "ORIGINAL CHUNK:\n",
      "----------------------------------------\n",
      "问题也随之⽽来。为⼈⼯智能的开发\n",
      "和部署建⽴清晰的指导⽅针和道德框架⾄关重要。\n",
      "⼈⼯智能武器化\n",
      "⼈⼯智能在⾃主武器系统中的潜在应⽤引发了重⼤的伦理和安全担忧。需要开展国际讨论并制定相\n",
      "关法规，以应对⼈⼯智能武器的相关⻛险。\n",
      "第五章：⼈⼯智能的未来\n",
      "⼈⼯智能的未来很可能以持续进步和在各个领域的⼴泛应⽤为特征。关键趋势和发展领域包括：\n",
      "可解释⼈⼯智能（XAI）\n",
      "可解释⼈⼯智能 (XAI) 旨在使⼈⼯智能系统更加透明易懂。XAI 技术正在开发中，旨在深⼊了解⼈\n",
      "⼯智能模型的决策⽅式，从⽽增强信任度和责任感。\n",
      "边缘⼈⼯智能\n",
      "边缘⼈⼯智能是指在设备上本地处理数据，⽽不是依赖云服务器。这种⽅法可以减少延迟，增强隐\n",
      "私保护，并在连接受限的环境中⽀持⼈⼯智能应⽤。\n",
      "量⼦计算和⼈⼯智能\n",
      "量⼦计算有望显著加速⼈⼯智能算法，从⽽推动药物研发、材料科学和优化等领域的突破。量⼦计\n",
      "算与⼈⼯智能的交叉研究前景⼴阔。\n",
      "⼈机协作\n",
      "⼈⼯智能的未来很可能涉及⼈类与⼈⼯智能系统之间更紧密的协作。这包括开发能够增强⼈类能\n",
      "⼒、⽀持决策和提⾼⽣产⼒的⼈⼯智能⼯具。\n",
      "⼈⼯智能造福社会\n",
      "⼈⼯智能正⽇益被⽤于应对社会和环境挑战，例如⽓候变化、贫困和医疗保健差距。“⼈⼯智能造\n",
      "福社会”倡议旨在利⽤⼈⼯智能产⽣积极影响。\n",
      "监管与治理\n",
      "随着⼈⼯智能⽇益普及，监管和治理的需求将⽇益增⻓，以确保负责任的开发和部署。这包括制定\n",
      "道德准则、解决偏⻅和公平问题，以及保护隐私和安全。国际标准合作⾄关重要。\n",
      "通过了解⼈⼯智能的核⼼概念、应⽤、伦理影响和未来发展⽅向，我们可以更好地应对这项变⾰性\n",
      "技术带来的机遇和挑战。持续的研究、负责任的开发和周到的治理，对于充分发挥⼈⼯智能的潜⼒\n",
      "并降低其⻛险⾄关重要。\n",
      "第六章：⼈⼯智能和机器⼈技术\n",
      "⼈⼯智能与机器⼈技术的融合\n",
      "⼈⼯智能与机器⼈技术的融合，将机器⼈的物理能⼒与⼈⼯智能的认知能⼒完美结合。这种... [truncated]\n",
      "----------------------------------------\n",
      "Length: 1000 characters\n",
      "\n",
      "COMPRESSED CHUNK:\n",
      "----------------------------------------\n",
      "人工智能在决策应用中的伦理问题包括：\n",
      "1. 需要建立道德框架和指导方针\n",
      "2. 自主武器系统引发安全担忧\n",
      "3. 可解释人工智能(XAI)技术旨在提高决策透明度\n",
      "4. 监管需求增加，需制定道德准则、解决偏见和公平问题\n",
      "5. 国际标准合作对负责任开发至关重要\n",
      "----------------------------------------\n",
      "Length: 126 characters\n",
      "Compression ratio: 87.40%\n",
      "\n",
      "Average compression across all chunks: 87.48%\n",
      "Total context length reduction: 87.48%\n",
      "================================================================================\n",
      "\n",
      "=== EXTRACTION COMPRESSION EXAMPLE ===\n",
      "\n",
      "ORIGINAL CHUNK:\n",
      "----------------------------------------\n",
      "问题也随之⽽来。为⼈⼯智能的开发\n",
      "和部署建⽴清晰的指导⽅针和道德框架⾄关重要。\n",
      "⼈⼯智能武器化\n",
      "⼈⼯智能在⾃主武器系统中的潜在应⽤引发了重⼤的伦理和安全担忧。需要开展国际讨论并制定相\n",
      "关法规，以应对⼈⼯智能武器的相关⻛险。\n",
      "第五章：⼈⼯智能的未来\n",
      "⼈⼯智能的未来很可能以持续进步和在各个领域的⼴泛应⽤为特征。关键趋势和发展领域包括：\n",
      "可解释⼈⼯智能（XAI）\n",
      "可解释⼈⼯智能 (XAI) 旨在使⼈⼯智能系统更加透明易懂。XAI 技术正在开发中，旨在深⼊了解⼈\n",
      "⼯智能模型的决策⽅式，从⽽增强信任度和责任感。\n",
      "边缘⼈⼯智能\n",
      "边缘⼈⼯智能是指在设备上本地处理数据，⽽不是依赖云服务器。这种⽅法可以减少延迟，增强隐\n",
      "私保护，并在连接受限的环境中⽀持⼈⼯智能应⽤。\n",
      "量⼦计算和⼈⼯智能\n",
      "量⼦计算有望显著加速⼈⼯智能算法，从⽽推动药物研发、材料科学和优化等领域的突破。量⼦计\n",
      "算与⼈⼯智能的交叉研究前景⼴阔。\n",
      "⼈机协作\n",
      "⼈⼯智能的未来很可能涉及⼈类与⼈⼯智能系统之间更紧密的协作。这包括开发能够增强⼈类能\n",
      "⼒、⽀持决策和提⾼⽣产⼒的⼈⼯智能⼯具。\n",
      "⼈⼯智能造福社会\n",
      "⼈⼯智能正⽇益被⽤于应对社会和环境挑战，例如⽓候变化、贫困和医疗保健差距。“⼈⼯智能造\n",
      "福社会”倡议旨在利⽤⼈⼯智能产⽣积极影响。\n",
      "监管与治理\n",
      "随着⼈⼯智能⽇益普及，监管和治理的需求将⽇益增⻓，以确保负责任的开发和部署。这包括制定\n",
      "道德准则、解决偏⻅和公平问题，以及保护隐私和安全。国际标准合作⾄关重要。\n",
      "通过了解⼈⼯智能的核⼼概念、应⽤、伦理影响和未来发展⽅向，我们可以更好地应对这项变⾰性\n",
      "技术带来的机遇和挑战。持续的研究、负责任的开发和周到的治理，对于充分发挥⼈⼯智能的潜⼒\n",
      "并降低其⻛险⾄关重要。\n",
      "第六章：⼈⼯智能和机器⼈技术\n",
      "⼈⼯智能与机器⼈技术的融合\n",
      "⼈⼯智能与机器⼈技术的融合，将机器⼈的物理能⼒与⼈⼯智能的认知能⼒完美结合。这种... [truncated]\n",
      "----------------------------------------\n",
      "Length: 1000 characters\n",
      "\n",
      "COMPRESSED CHUNK:\n",
      "----------------------------------------\n",
      "为⼈⼯智能的开发\n",
      "和部署建⽴清晰的指导⽅针和道德框架⾄关重要。\n",
      "⼈⼯智能在⾃主武器系统中的潜在应⽤引发了重⼤的伦理和安全担忧。\n",
      "需要开展国际讨论并制定相\n",
      "关法规，以应对⼈⼯智能武器的相关⻛险。\n",
      "随着⼈⼯智能⽇益普及，监管和治理的需求将⽇益增⻓，以确保负责任的开发和部署。\n",
      "这包括制定\n",
      "道德准则、解决偏⻅和公平问题，以及保护隐私和安全。\n",
      "----------------------------------------\n",
      "Length: 167 characters\n",
      "Compression ratio: 83.30%\n",
      "\n",
      "Average compression across all chunks: 82.91%\n",
      "Total context length reduction: 82.91%\n",
      "================================================================================\n",
      "\n",
      "=== COMPRESSION SUMMARY ===\n",
      "\n",
      "Technique       Avg Ratio       Context Length  Original Length\n",
      "------------------------------------------------------------\n",
      "selective       77.73%          2081            9489           \n",
      "summary         87.48%          1186            9489           \n",
      "extraction      82.91%          1564            9489           \n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
